---
article: "/ai-can-be-objective-or-unbiased"
title: "Bibliography & Resources"
position: 1
---
###Videos:
[Tutorial on Fairness Accountability Transparency and Ethics in Computer Vision](https://sites.google.com/view/fatecv-tutorial/schedule?authuser=0) - Timnit Gebru & Emily Denton
- Description [here](https://sites.google.com/view/fatecv-tutorial/home)

[Politics of AI](https://www.youtube.com/watch?v=HPopJb5aDyA) - Kate Crawford

For more video resources and a list of books, check out [this list from the UCLA Center for Critical Internet Inquiry](https://docs.google.com/document/d/1moEbUugiG9u2x2HRlBXN0PGk4h5Sb-1993elBj4oHac/edit)

###Interactive games/tools:
[Survival of the best fit](https://github.com/survivalofthebestfit/survivalofthebestfit)

[MIT Tech Review game on AI bias](https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/)

###Introductory explainers on bias in AI

[MIT Tech Review: This is how AI bias really happens—and why it’s so hard to fix](https://www.technologyreview.com/2019/02/04/137602/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/)

[Why do ML systems exhibit bias?](https://medium.com/@dab055/blog-1-60176616bb2c)

[Bias in the Vision and Language of Artificial Intelligence](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture19-bias.pdf)

[The Hill - why are AI systems biased?](https://thehill.com/opinion/cybersecurity/506924-why-are-artificial-intelligence-systems-biased) 

[The foundations of AI bias](http://approximatelycorrect.com/2016/11/07/the-foundations-of-algorithmic-bias/) - Zachary Lipton

[IBM: ML and bias](https://developer.ibm.com/technologies/machine-learning/articles/machine-learning-and-bias/)

[World Economic Forum: How to Prevent Discriminatory Outcomes in Machine Learning](http://www3.weforum.org/docs/WEF_40065_White_Paper_How_to_Prevent_Discriminatory_Outcomes_in_Machine_Learning.pdf)

[What is the Fairness Accountability and Transparecy (FAccT) machine learning model?](https://www.thinkautomation.com/eli5/what-is-the-fat-machine-learning-model/)

[The quest to make AI less prejudiced](https://www.cis.upenn.edu/~mkearns/quartzbias.pdf)

[Understanding and Reducing Bias in Machine Learning](https://towardsdatascience.com/understanding-and-reducing-bias-in-machine-learning-6565e23900ac)

[UK Government Interim report on Automated Decision Making bias](https://www.gov.uk/government/publications/interim-reports-from-the-centre-for-data-ethics-and-innovation/interim-report-review-into-bias-in-algorithmic-decision-making)

[UK Government: Landscape summary - Bias in Automated Decision Making](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/819055/Landscape_Summary_-_Bias_in_Algorithmic_Decision-Making.pdf )

###AI and racism/sexism
[Data Racism - European Network Against Racism](https://www.enar-eu.org/Data-racism-a-new-frontier )

[Social Inequality Will Not Be Solved By an App](https://www.wired.com/story/social-inequality-will-not-be-solved-by-an-app/) - Safiya Noble
- Her reading list on bias in algorithms:
 https://blog.getpocket.com/2020/06/the-bias-embedded-in-algorithms/

 [Google Ad Portal Equated “Black Girls” with Porn](https://themarkup.org/google-the-giant/2020/07/23/google-advertising-keywords-black-girls)

[The Algorithmic Colonization of Africa](https://reallifemag.com/the-algorithmic-colonization-of-africa/)

[Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence](https://arxiv.org/abs/2007.04068)
- Verge article on this paper: [DeepMind researchers propose rebuilding the AI industry on a base of anticolonialism](https://venturebeat.com/2020/07/11/deepmind-researchers-propose-rebuilding-the-ai-industry-on-a-base-of-anticolonialism/)

[How surveillance has always reinforced racism](https://www.wired.com/story/how-surveillance-reinforced-racism/) - Simone Browne

[Algorithms that run our lives are racist and sexist. Meet the women trying to fix them](https://thecorrespondent.com/339/algorithms-that-run-our-lives-are-racist-and-sexist-meet-the-women-trying-to-fix-them/2780342400-b3a2696a )

[The enduring anti-black racism of Google search](https://onezero.medium.com/the-enduring-anti-black-racism-of-google-search-d024924bff77)
- "Framing the problems as “pipeline” issues instead of as an issue of racism and sexism, which extends from employment practices to product design. “Black girls need to learn how to code” is an excuse for not addressing the persistent marginalization of Black women in Silicon Valley"

[Defund Facial Recognition](https://www.theatlantic.com/technology/archive/2020/07/defund-facial-recognition/613771/)

[Policing’s problems won’t be fixed by tech that aids—or replaces—humans](https://www.fastcompany.com/90528635/policings-problems-wont-be-fixed-by-tech-that-aids-or-replaces-humans?partner=rss&utm_source=twitter.com&utm_medium=social&utm_campaign=rss+fastcompany&utm_content=rss)

[AI Now report on diversity in AI industry](https://ainowinstitute.org/discriminatingsystems.pdf)
- Verge article on this report: [The artificial intelligence field is too white and too male, researchers say](https://www.theverge.com/2019/4/16/18410501/artificial-intelligence-ai-diversity-report-facial-recognition)

E. Tendayi Achiume: [Racial discrimination and emerging digital technologies: a human rights analysis - Report of the Special Rapporteur on contemporary forms of racism, racial discrimination, xenophobia and related intolerance](https://antiracismsr.org/wp-content/uploads/2020/07/A_HRC_44_57_AdvanceEditedVersion.pdf )

[What a machine learning tool that turns Obama white can (and can’t) tell us about AI bias](https://www.theverge.com/21298762/face-depixelizer-ai-machine-learning-tool-pulse-stylegan-obama-bias )

[The Great White Robot God - Artificial General Intelligence and White Supremacy](https://medium.com/@davidgolumbia/the-great-white-robot-god-bea8e23943da)

[MIT apologizes, permanently pulls offline huge dataset that taught AI systems to use racist, misogynistic slurs](https://www.theregister.com/2020/07/01/mit_dataset_removed/)

[Indigenous AI](http://www.indigenous-ai.net/position-paper)

[How afrofuturusm can help the world mend](https://www.wired.com/story/how-afrofuturism-can-help-the-world-mend/)

[The racist history behind facial recognition](https://www.nytimes.com/2019/07/10/opinion/facial-recognition-race.html)

[Our Face Recognition Nightmare Began Decades Ago. Now It’s Expanding](https://www.vice.com/en_us/article/d3a7ym/trump-didnt-create-our-face-recognition-nightmare-hes-just-expanding-it ) - Os Keyes

[The activist dismantling racist police algorithms](https://www.technologyreview.com/2020/06/05/1002709/the-activist-dismantling-racist-police-algorithms/ )

[Why racial bias is still inherent in biometric tech](https://www.raconteur.net/technology/biometrics-ethics-bias )

[Beyond the Algorithm: Pretrial Reform, Risk Assessment, and Racial Fairness](https://www.courtinnovation.org/publications/beyond-algorithm )

[Can racist algorithms be fixed?](https://www.themarshallproject.org/2019/07/01/can-racist-algorithms-be-fixed )

[Gender bias in GPT2](https://towardsdatascience.com/gender-bias-in-gpt-2-acf65dc84bd8)

###Famous cases of bias in AI systems
[Gender Shades](http://gendershades.org/)

[How racial bias infected a major health-care algorithm](https://review.chicagobooth.edu/economics/2019/article/how-racial-bias-infected-major-health-care-algorithm)
- Based on [Dissecting racial bias in an algorithm used to manage the health of populations](https://escholarship.org/content/qt6h92v832/qt6h92v832.pdf)

###AI can fix bias
[Data Innovation: Could AI help reduce gender bias in Europe?](https://www.neweurope.eu/article/could-ai-help-reduce-gender-bias-in-europe/)

[Biased Algorithms Are Easier to Fix Than Biased People](https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html)
- Based on this paper: [Discrimination in the Age of Algorithms](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3329669)

[An AI hiring firm says it can predict job hopping based on your interviews](https://www.technologyreview.com/2020/07/24/1005602/ai-hiring-promises-bias-free-job-hopping-prediction/)

[Mitigating Bias in Algorithmic Hiring: Evaluating Claims and Practices](https://arxiv.org/abs/1906.09208)

###Against the bias framing
[The seductive diversion of trying to solve AI bias](https://onezero.medium.com/the-seductive-diversion-of-solving-bias-in-artificial-intelligence-890df5e5ef53) - Julia Powles

[Systemic algorithmic harms](https://points.datasociety.net/systemic-algorithmic-harms-e00f99e72c42) - Kinjal Dave

[A Broader View on Bias in Automated Decision-Making: Reflecting on Epistemology and Dynamics](https://arxiv.org/abs/1807.00553)

[Technology can’t fix algorithmic injustice](https://bostonreview.net/science-nature-politics/annette-zimmermann-elena-di-rosa-hochan-kim-technology-cant-fix-algorithmic) - Annette Zimmermann, Elena Di Rosa, Hochan Kim

[The Long History of Algorithmic Fairness](https://phenomenalworld.org/analysis/long-history-algorithmic-fairness)

Timnit Gebur & Emily Denton - [Tutorial on Fairness Accountability Transparency and Ethics in Computer Vision](https://sites.google.com/view/fatecv-tutorial/home)

[Ruha Benjamin on deep learning: Computational depth without sociological depth is ‘superficial learning’](https://venturebeat.com/2020/04/29/ruha-benjamin-on-deep-learning-computational-depth-without-sociological-depth-is-superficial-learning/)

[The False Promise of Risk Assessments: Epistemic Reform and the Limits of Fairness](https://scholar.harvard.edu/files/bgreen/files/20-fat-risk.pdf)

[Fairness, Equality, and Power in Algorithmic Decision-Making](https://maxkasy.github.io/home/files/papers/fairness_equality_power.pdf)

[Questioning the assumptions behind fairness solutions](https://arxiv.org/abs/1811.11293) - Rebekah Overdorf, Bogdan Kulynych, Ero Balsa, Carmela Troncoso, Seda Gürses
- The above is a short version of this: [POTs: Protective Optimization Technologies](https://arxiv.org/abs/1806.02711)
- And this is an interview with the authors on the topic: [Optimizing the Crisis](https://phenomenalworld.org/interviews/counter-optimizing-the-crisis)

[The full force of the state](https://aboutintel.eu/predictive-policing-context/) - Fieke Jansen
- "...this article argues that in the decision-making around whether or not to use predictive policing, it is crucial to look beyond the issues of the tool itself and critically reflect on its perceived added value and the issues around the fairness and legitimacy of the entire intervention, not just the tool. Debating the issue, we must ask whether the desire to innovate or tackle a specific security problem can come at the expense of individual and collective fundamental human rights. Furthermore, when challenging these technologies it is equally important to understand the incentives that drive police to turn to these technologies."

[Why Hundreds of Mathematicians Are Boycotting Predictive Policing](https://www.popularmechanics.com/science/math/a32957375/mathematicians-boycott-predictive-policing/?utm_source=pocket-newtab)

[Why Fairness Cannot Be Automated: Bridging the Gap Between EU Non-Discrimination Law and AI](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3547922) - Sandra Wachter

[Decentering technology in discourse on discrimination](https://www.tandfonline.com/doi/full/10.1080/1369118X.2019.1593484)

###Technical explainers on bias
[Bias in Artificial Intelligence (from a practicioner perspective)](https://towardsdatascience.com/bias-in-artificial-intelligence-a3239ce316c9)

[Do You Believe in FAIR-y-tales? An Overview of Microsoft’s New Toolkit for Assessing and Improving Fairness of Algorithms](https://www.law.kuleuven.be/citip/blog/do-you-believe-in-fair-y-tales-an-overview-of-microsofts-new-toolkit-for-assessing-and-improving-fairness-of-algorithms/)

The bias-variance tradeoff
- [Bias Variance](http://scott.fortmann-roe.com/docs/BiasVariance.html)
- [Gentle introduction to the bias-variance tradeoff in machine learning](https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/)
- [ML: bias vs variance](https://becominghuman.ai/machine-learning-bias-vs-variance-641f924e6c57)
- [Bias variance tradeoff](https://towardsdatascience.com/bias-variance-trade-off-a-360-degree-view-86648f69f8)

[Fair ML book](https://fairmlbook.org/pdf/fairmlbook.pdf)

[Algorithmic bias in autonomous systems](https://www.researchgate.net/publication/318830422_Algorithmic_Bias_in_Autonomous_Systems )
- Explains the ‘neutral’ technical use of bias as deviation from a standard
- “The word ‘bias’ often has a negative connotation in the English language; bias is something to be avoided, or that is necessarily problematic. In contrast, we understand the term in an older, more neutral way: ‘bias’ simply refers to deviation from a standard. Thus, we can have statistical bias in which an estimate deviates from a statistical standard (e.g., the true population value); moral bias in which a judgment deviates from a moral norm; and similarly for regulatory or legal bias, social bias, psychological bias, and others. More generally, there are many types of bias depending on the type of standard being used.”

###Academic articles on bias
[Timnit Gebru & Eun Seo Jo - Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning](https://arxiv.org/pdf/1912.10389.pdf)

[Bias in Computer Systems](https://dl.acm.org/doi/pdf/10.1145/230538.230561) - Helen Nissenbaum

[Big Data’s Disparate Impact](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899) - Andrew Selbst

[Bringing the People Back In: Contesting Benchmark Machine Learning Datasets](https://arxiv.org/abs/2007.07399)

[A Survey on Bias and Fairness in Machine Learning](https://arxiv.org/pdf/1908.09635.pdf)

[Predictive Biases in Natural Language Processing Models:A Conceptual Framework and Overview](https://arxiv.org/pdf/1912.11078.pdf)

[Privacy as Protection of the Incomputable Self: From Agnostic to Agonistic Machine Learning](http://din-online.info/pdf/th20-1-6.pdf) - Mireille Hildebrant 

[Fairness and Abstraction in Sociotechnical Systems](https://dl.acm.org/doi/10.1145/3287560.3287598) - Andrew Selbst et al: 

[The Woman Worked as a Babysitter: On Biases in Language Generation](https://arxiv.org/pdf/1909.01326.pdf )

[Feminist AI: Can We Expect Our AI Systems to Become Feminist?](https://link.springer.com/article/10.1007/s13347-019-00352-z)

[Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/abs/1607.06520)

[Social Data: Biases, Methodological Pitfalls, and Ethical Boundaries](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2886526)

[Inherent Trade-Offs in the Fair Determination of Risk Scores](https://arxiv.org/pdf/1609.05807v1.pdf )

[Fair prediction with disparate impact: A study of bias in recidivism prediction instruments](https://arxiv.org/pdf/1703.00056.pdf) - Alexandra Chouldechova

[Fairer and more accurate, but for whom?](https://arxiv.org/abs/1707.00046) - Alexandra Chouldechova, Max G'Sell

[Large image datasets: A pyrrhic win for computer vision?](https://openreview.net/forum?id=s-e2zaAlG3I)

[Gender bias in natural language processing](https://arxiv.org/abs/1807.11714 )

[Social Data: Biases, Methodological Pitfalls, and Ethical Boundaries](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2886526&download=yes)

[On the illusion of objectivity in natural language processing](https://openreview.net/pdf?id=fkAxTMzy3fs )

[Fairness Definitions Explained](https://fairware.cs.umass.edu/papers/Verma.pdf )

[Feminist claims to technical language](https://www.tandfonline.com/doi/full/10.1080/14680777.2020.1783797)
